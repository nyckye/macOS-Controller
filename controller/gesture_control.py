import cv2
import mediapipe as mp
import pyautogui
import time
import math
import numpy as np
from collections import deque
import sys
import os

class UltimateAIController:
    def __init__(self):
        # MediaPipe –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
        self.mp_hands = mp.solutions.hands
        self.hands = self.mp_hands.Hands(
            static_image_mode=False,
            max_num_hands=1,
            min_detection_confidence=0.8,
            min_tracking_confidence=0.8
        )
        
        self.mp_face_mesh = mp.solutions.face_mesh
        self.face_mesh = self.mp_face_mesh.FaceMesh(
            max_num_faces=1,
            refine_landmarks=True,
            min_detection_confidence=0.7,
            min_tracking_confidence=0.7
        )
        
        self.mp_pose = mp.solutions.pose
        self.pose = self.mp_pose.Pose(
            static_image_mode=False,
            model_complexity=1,
            min_detection_confidence=0.5,
            min_tracking_confidence=0.5
        )
        
        self.mp_draw = mp.solutions.drawing_utils
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏
        pyautogui.FAILSAFE = True
        pyautogui.PAUSE = 0.1
        
        # –ñ–ï–°–¢–´
        self.gesture_cooldown = 2.5
        self.last_action_time = 0
        self.stable_gesture = None
        self.stable_count = 0
        self.stability_threshold = 10
        
        # –ì–õ–ê–ó–ê
        self.blink_history = deque(maxlen=100)
        self.eye_closed_start = None
        self.last_blink_time = 0
        self.blink_count = 0
        self.fatigue_threshold = 20
        self.long_blink_threshold = 1.5
        self.eye_action_cooldown = 3.0
        self.last_eye_action_time = 0
        
        # –ì–û–õ–û–í–ê - –ò–°–ü–†–ê–í–õ–ï–ù–û
        self.head_history = deque(maxlen=15)  # –ë–æ–ª—å—à–µ –∏—Å—Ç–æ—Ä–∏–∏ –¥–ª—è —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏—è
        self.head_action_cooldown = 3.0  # –£–≤–µ–ª–∏—á–µ–Ω–æ –¥–æ 3 —Å–µ–∫—É–Ω–¥
        self.last_head_action_time = 0
        self.head_calibrated = False
        self.head_baseline_angle = 0.0
        self.head_baseline_y = 0.5
        
        # –û–°–ê–ù–ö–ê - –ò–°–ü–†–ê–í–õ–ï–ù–û
        self.posture_history = deque(maxlen=30)
        self.good_posture_baseline = None
        self.posture_check_interval = 3.0  # –£–≤–µ–ª–∏—á–µ–Ω–æ –¥–æ 3 —Å–µ–∫—É–Ω–¥
        self.last_posture_check = 0
        self.slouch_warning_active = False
        self.slouch_count = 0
        self.good_posture_count = 0
        
        # –ö–∞–ª–∏–±—Ä–æ–≤–∫–∞ –æ—Å–∞–Ω–∫–∏ - –£–õ–£–ß–®–ï–ù–û
        self.calibration_mode = True
        self.calibration_frames = 0
        self.calibration_required = 90  # 3 —Å–µ–∫—É–Ω–¥—ã –ø—Ä–∏ 30 FPS
        self.calibration_data = []
        self.calibration_stage = "posture"  # "posture" –∏–ª–∏ "head"
        
        # –°—á–µ—Ç—á–∏–∫ –∫–∞–¥—Ä–æ–≤ –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
        self.frames_with_pose = 0
        self.frames_needed_for_detection = 5
        
        print("üöÄ –ü–û–õ–ù–ê–Ø AI –°–ò–°–¢–ï–ú–ê –ó–ê–ü–£–©–ï–ù–ê!")
        print("\n" + "="*60)
        print("üìã –£–ü–†–ê–í–õ–ï–ù–ò–ï –ñ–ï–°–¢–ê–ú–ò:")
        print("="*60)
        print("   ‚úã 5 –ø–∞–ª—å—Ü–µ–≤ ‚Üí –ù–æ–≤–∞—è –≤–∫–ª–∞–¥–∫–∞")
        print("   ‚úä –ö—É–ª–∞–∫ ‚Üí –ó–∞–∫—Ä—ã—Ç—å –≤–∫–ª–∞–¥–∫—É")
        print("   ‚úåÔ∏è  2 –ø–∞–ª—å—Ü–∞ ‚Üí –°–ª–µ–¥—É—é—â–∞—è –≤–∫–ª–∞–¥–∫–∞")
        print("   ‚òùÔ∏è  1 –ø–∞–ª–µ—Ü ‚Üí –ü—Ä–µ–¥—ã–¥—É—â–∞—è –≤–∫–ª–∞–¥–∫–∞")
        print("   ü§ô 3 –ø–∞–ª—å—Ü–∞ ‚Üí –û–±–Ω–æ–≤–∏—Ç—å —Å—Ç—Ä–∞–Ω–∏—Ü—É")
        print("   üëç 4 –ø–∞–ª—å—Ü–∞ ‚Üí Mission Control")
        print("\n" + "="*60)
        print("üëÅÔ∏è  –£–ü–†–ê–í–õ–ï–ù–ò–ï –ì–õ–ê–ó–ê–ú–ò:")
        print("="*60)
        print("   üòë –ó–∞–∫—Ä—ã—Ç—å –≥–ª–∞–∑–∞ 1.5—Å ‚Üí –ü–∞—É–∑–∞/–í–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ")
        print("   üò¥ –ß–∞—Å—Ç–æ–µ –º–æ—Ä–≥–∞–Ω–∏–µ ‚Üí –£–º–µ–Ω—å—à–∏—Ç—å —è—Ä–∫–æ—Å—Ç—å")
        print("   üëÄ –†–µ–¥–∫–æ–µ –º–æ—Ä–≥–∞–Ω–∏–µ ‚Üí –£–≤–µ–ª–∏—á–∏—Ç—å —è—Ä–∫–æ—Å—Ç—å")
        print("\n" + "="*60)
        print("üß† –£–ü–†–ê–í–õ–ï–ù–ò–ï –ì–û–õ–û–í–û–ô:")
        print("="*60)
        print("   ‚¨ÖÔ∏è  –ù–∞–∫–ª–æ–Ω –≤–ª–µ–≤–æ ‚Üí –ì—Ä–æ–º–∫–æ—Å—Ç—å ‚Üì")
        print("   ‚û°Ô∏è  –ù–∞–∫–ª–æ–Ω –≤–ø—Ä–∞–≤–æ ‚Üí –ì—Ä–æ–º–∫–æ—Å—Ç—å ‚Üë")
        print("   ‚¨ÜÔ∏è  –ù–∞–∫–ª–æ–Ω –Ω–∞–∑–∞–¥ ‚Üí –ü—Ä–æ–∫—Ä—É—Ç–∫–∞ –≤–≤–µ—Ä—Ö")
        print("   ‚¨áÔ∏è  –ù–∞–∫–ª–æ–Ω –≤–ø–µ—Ä–µ–¥ ‚Üí –ü—Ä–æ–∫—Ä—É—Ç–∫–∞ –≤–Ω–∏–∑")
        print("\n" + "="*60)
        print("üèÉ –ö–û–ù–¢–†–û–õ–¨ –û–°–ê–ù–ö–ò:")
        print("="*60)
        print("   üéØ –°–Ø–î–¨–¢–ï –†–û–í–ù–û –¥–ª—è –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏!")
        print("   ‚ö†Ô∏è  –°–∏—Å—Ç–µ–º–∞ –ø—Ä–µ–¥—É–ø—Ä–µ–¥–∏—Ç –æ —Å—É—Ç—É–ª–æ—Å—Ç–∏")
        print("   ‚úÖ –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ —à–µ–∏ –∏ –ø–ª–µ—á")
        print("\n‚å®Ô∏è  –ù–∞–∂–º–∏—Ç–µ 'q' –¥–ª—è –≤—ã—Ö–æ–¥–∞\n")
    
    # ============= –ñ–ï–°–¢–´ –†–£–ö =============
    
    def count_fingers_optimized(self, hand_landmarks):
        """–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–æ–¥—Å—á–µ—Ç –ø–∞–ª—å—Ü–µ–≤"""
        fingers = []
        landmarks = hand_landmarks.landmark
        
        wrist = landmarks[0]
        middle_base = landmarks[9]
        is_right_hand = wrist.x < middle_base.x
        
        # –ë–æ–ª—å—à–æ–π –ø–∞–ª–µ—Ü
        thumb_tip = landmarks[4]
        thumb_base = landmarks[2]
        if is_right_hand:
            fingers.append(1 if thumb_tip.x < thumb_base.x else 0)
        else:
            fingers.append(1 if thumb_tip.x > thumb_base.x else 0)
        
        # –û—Å—Ç–∞–ª—å–Ω—ã–µ –ø–∞–ª—å—Ü—ã
        finger_tips = [8, 12, 16, 20]
        finger_mids = [6, 10, 14, 18]
        
        for tip, mid in zip(finger_tips, finger_mids):
            if landmarks[tip].y < landmarks[mid].y:
                fingers.append(1)
            else:
                fingers.append(0)
        
        return sum(fingers)
    
    def calculate_hand_confidence(self, hand_landmarks):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –≤ –∂–µ—Å—Ç–µ"""
        landmarks = hand_landmarks.landmark
        wrist = np.array([landmarks[0].x, landmarks[0].y])
        middle_finger = np.array([landmarks[9].x, landmarks[9].y])
        distance = np.linalg.norm(middle_finger - wrist)
        return 0.15 < distance < 0.4
    
    def get_gesture_name(self, finger_count):
        gestures = {
            0: "–ö—É–ª–∞–∫", 1: "–û–¥–∏–Ω –ø–∞–ª–µ—Ü", 2: "–î–≤–∞ –ø–∞–ª—å—Ü–∞",
            3: "–¢—Ä–∏ –ø–∞–ª—å—Ü–∞", 4: "–ß–µ—Ç—ã—Ä–µ –ø–∞–ª—å—Ü–∞", 5: "–û—Ç–∫—Ä—ã—Ç–∞—è –ª–∞–¥–æ–Ω—å"
        }
        return gestures.get(finger_count, "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ")
    
    def execute_gesture_action(self, finger_count):
        """–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∂–µ—Å—Ç–∞"""
        current_time = time.time()
        
        if current_time - self.last_action_time < self.gesture_cooldown:
            return
        
        actions = {
            5: ("–ù–æ–≤–∞—è –≤–∫–ª–∞–¥–∫–∞", lambda: pyautogui.hotkey('command', 't')),
            0: ("–ó–∞–∫—Ä—ã—Ç—å –≤–∫–ª–∞–¥–∫—É", lambda: pyautogui.hotkey('command', 'w')),
            2: ("–í–∫–ª–∞–¥–∫–∞ –≤–ø—Ä–∞–≤–æ", lambda: pyautogui.hotkey('command', 'shift', ']')),
            1: ("–í–∫–ª–∞–¥–∫–∞ –≤–ª–µ–≤–æ", lambda: pyautogui.hotkey('command', 'shift', '[')),
            3: ("–û–±–Ω–æ–≤–∏—Ç—å —Å—Ç—Ä–∞–Ω–∏—Ü—É", lambda: pyautogui.hotkey('command', 'r')),
            4: ("Mission Control", lambda: pyautogui.hotkey('ctrl', 'up'))
        }
        
        if finger_count in actions:
            action_name, action_func = actions[finger_count]
            try:
                action_func()
                self.last_action_time = current_time
                print(f"‚úÖ –ñ–µ—Å—Ç: {action_name}")
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
    
    # ============= –ì–õ–ê–ó–ê =============
    
    def calculate_eye_aspect_ratio(self, landmarks, eye_indices):
        """EAR –¥–ª—è –º–æ—Ä–≥–∞–Ω–∏—è"""
        vertical1 = math.dist(
            [landmarks[eye_indices[1]].x, landmarks[eye_indices[1]].y],
            [landmarks[eye_indices[5]].x, landmarks[eye_indices[5]].y]
        )
        vertical2 = math.dist(
            [landmarks[eye_indices[2]].x, landmarks[eye_indices[2]].y],
            [landmarks[eye_indices[4]].x, landmarks[eye_indices[4]].y]
        )
        horizontal = math.dist(
            [landmarks[eye_indices[0]].x, landmarks[eye_indices[0]].y],
            [landmarks[eye_indices[3]].x, landmarks[eye_indices[3]].y]
        )
        
        ear = (vertical1 + vertical2) / (2.0 * horizontal)
        return ear
    
    def detect_eye_state(self, face_landmarks):
        """–°–æ—Å—Ç–æ—è–Ω–∏–µ –≥–ª–∞–∑"""
        LEFT_EYE = [362, 385, 387, 263, 373, 380]
        RIGHT_EYE = [33, 160, 158, 133, 153, 144]
        
        landmarks = face_landmarks.landmark
        left_ear = self.calculate_eye_aspect_ratio(landmarks, LEFT_EYE)
        right_ear = self.calculate_eye_aspect_ratio(landmarks, RIGHT_EYE)
        avg_ear = (left_ear + right_ear) / 2.0
        
        return avg_ear < 0.2, avg_ear
    
    def handle_eye_actions(self, eyes_closed, current_time):
        """–î–µ–π—Å—Ç–≤–∏—è –≥–ª–∞–∑–∞–º–∏"""
        if current_time - self.last_eye_action_time < self.eye_action_cooldown:
            return
        
        if eyes_closed:
            if self.eye_closed_start is None:
                self.eye_closed_start = current_time
            else:
                closed_duration = current_time - self.eye_closed_start
                if closed_duration >= self.long_blink_threshold:
                    try:
                        pyautogui.press('space')
                        print("üëÅÔ∏è  –ì–ª–∞–∑–∞: –ü–∞—É–∑–∞/–í–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ")
                        self.last_eye_action_time = current_time
                        self.eye_closed_start = None
                    except:
                        pass
        else:
            if self.eye_closed_start is not None:
                closed_duration = current_time - self.eye_closed_start
                if closed_duration < self.long_blink_threshold:
                    self.blink_count += 1
                    self.blink_history.append(current_time)
                self.eye_closed_start = None
    
    def check_eye_fatigue(self, current_time):
        """–£—Å—Ç–∞–ª–æ—Å—Ç—å –≥–ª–∞–∑"""
        while self.blink_history and current_time - self.blink_history[0] > 60:
            self.blink_history.popleft()
        
        blinks_per_minute = len(self.blink_history)
        
        if blinks_per_minute > self.fatigue_threshold:
            if current_time - self.last_eye_action_time > 10:
                try:
                    import subprocess
                    subprocess.run(['osascript', '-e', 
                                  'tell application "System Events" to key code 107'], 
                                  capture_output=True, timeout=1)
                    print(f"üò¥ –£—Å—Ç–∞–ª–æ—Å—Ç—å –≥–ª–∞–∑ ({blinks_per_minute} –º–æ—Ä–≥/–º–∏–Ω) ‚Üí –Ø—Ä–∫–æ—Å—Ç—å ‚Üì")
                    self.last_eye_action_time = current_time
                except:
                    pass
        
        return blinks_per_minute
    
    # ============= –ì–û–õ–û–í–ê - –ò–°–ü–†–ê–í–õ–ï–ù–û =============
    
    def calculate_head_pose(self, face_landmarks):
        """–í—ã—á–∏—Å–ª–µ–Ω–∏–µ –ø–æ–∑—ã –≥–æ–ª–æ–≤—ã"""
        landmarks = face_landmarks.landmark
        
        # –ö–ª—é—á–µ–≤—ã–µ —Ç–æ—á–∫–∏
        left_ear = np.array([landmarks[234].x, landmarks[234].y])
        right_ear = np.array([landmarks[454].x, landmarks[454].y])
        nose_tip = landmarks[1]
        
        # –£–≥–æ–ª –Ω–∞–∫–ª–æ–Ω–∞ –≥–æ–ª–æ–≤—ã (–ª–µ–≤–æ/–ø—Ä–∞–≤–æ)
        ear_angle = math.atan2(right_ear[1] - left_ear[1], right_ear[0] - left_ear[0])
        
        # –í—ã—Å–æ—Ç–∞ –Ω–æ—Å–∞ (–≤–≤–µ—Ä—Ö/–≤–Ω–∏–∑)
        nose_y = nose_tip.y
        
        return ear_angle, nose_y
    
    def calibrate_head(self):
        """–ö–∞–ª–∏–±—Ä–æ–≤–∫–∞ –Ω–µ–π—Ç—Ä–∞–ª—å–Ω–æ–≥–æ –ø–æ–ª–æ–∂–µ–Ω–∏—è –≥–æ–ª–æ–≤—ã"""
        if len(self.head_history) >= 15 and not self.head_calibrated:
            # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ä–µ–¥–Ω–µ–µ –Ω–µ–π—Ç—Ä–∞–ª—å–Ω–æ–µ –ø–æ–ª–æ–∂–µ–Ω–∏–µ
            angles = [h[0] for h in self.head_history]
            ys = [h[1] for h in self.head_history]
            
            self.head_baseline_angle = np.mean(angles)
            self.head_baseline_y = np.mean(ys)
            self.head_calibrated = True
            
            print(f"‚úÖ –ì–æ–ª–æ–≤–∞ –æ—Ç–∫–∞–ª–∏–±—Ä–æ–≤–∞–Ω–∞! –ë–∞–∑–æ–≤—ã–π —É–≥–æ–ª: {self.head_baseline_angle:.2f}, Y: {self.head_baseline_y:.2f}")
            return True
        return False
    
    def handle_head_actions(self, ear_angle, nose_y, current_time):
        """–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –≥–æ–ª–æ–≤–æ–π - –ò–°–ü–†–ê–í–õ–ï–ù–û"""
        if current_time - self.last_head_action_time < self.head_action_cooldown:
            return
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏—Å—Ç–æ—Ä–∏—é
        self.head_history.append((ear_angle, nose_y))
        
        # –ö–∞–ª–∏–±—Ä–æ–≤–∫–∞ –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∑–∞–ø—É—Å–∫–µ
        if not self.head_calibrated:
            self.calibrate_head()
            return
        
        if len(self.head_history) < 10:
            return
        
        # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ä–µ–¥–Ω–µ–µ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ –∫–∞–¥—Ä—ã
        recent_angles = [h[0] for h in list(self.head_history)[-10:]]
        recent_ys = [h[1] for h in list(self.head_history)[-10:]]
        
        avg_angle = np.mean(recent_angles)
        avg_y = np.mean(recent_ys)
        
        # –û—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ –æ—Ç –±–∞–∑–æ–≤–æ–≥–æ –ø–æ–ª–æ–∂–µ–Ω–∏—è
        angle_diff = avg_angle - self.head_baseline_angle
        y_diff = avg_y - self.head_baseline_y
        
        # –ù–∞–∫–ª–æ–Ω –≤–ª–µ–≤–æ/–≤–ø—Ä–∞–≤–æ (–≥—Ä–æ–º–∫–æ—Å—Ç—å) - –£–í–ï–õ–ò–ß–ï–ù –ü–û–†–û–ì
        if angle_diff > 0.25:  # –ë—ã–ª–æ 0.15, —Å—Ç–∞–ª–æ 0.25
            try:
                import subprocess
                subprocess.run(['osascript', '-e', 
                              'set volume output volume ((output volume of (get volume settings)) + 10)'],
                              capture_output=True, timeout=1)
                print("‚û°Ô∏è  –ì–æ–ª–æ–≤–∞ –≤–ø—Ä–∞–≤–æ: –ì—Ä–æ–º–∫–æ—Å—Ç—å ‚Üë")
                self.last_head_action_time = current_time
            except:
                pass
        elif angle_diff < -0.25:  # –ë—ã–ª–æ -0.15, —Å—Ç–∞–ª–æ -0.25
            try:
                import subprocess
                subprocess.run(['osascript', '-e', 
                              'set volume output volume ((output volume of (get volume settings)) - 10)'],
                              capture_output=True, timeout=1)
                print("‚¨ÖÔ∏è  –ì–æ–ª–æ–≤–∞ –≤–ª–µ–≤–æ: –ì—Ä–æ–º–∫–æ—Å—Ç—å ‚Üì")
                self.last_head_action_time = current_time
            except:
                pass
        # –ù–∞–∫–ª–æ–Ω –≤–ø–µ—Ä–µ–¥/–Ω–∞–∑–∞–¥ (–ø—Ä–æ–∫—Ä—É—Ç–∫–∞) - –£–í–ï–õ–ò–ß–ï–ù –ü–û–†–û–ì
        elif y_diff > 0.08:  # –ë—ã–ª–æ 0.05, —Å—Ç–∞–ª–æ 0.08
            try:
                pyautogui.scroll(-3)
                print("‚¨áÔ∏è  –ì–æ–ª–æ–≤–∞ –≤–ø–µ—Ä–µ–¥: –ü—Ä–æ–∫—Ä—É—Ç–∫–∞ –≤–Ω–∏–∑")
                self.last_head_action_time = current_time
            except:
                pass
        elif y_diff < -0.08:  # –ë—ã–ª–æ -0.05, —Å—Ç–∞–ª–æ -0.08
            try:
                pyautogui.scroll(3)
                print("‚¨ÜÔ∏è  –ì–æ–ª–æ–≤–∞ –Ω–∞–∑–∞–¥: –ü—Ä–æ–∫—Ä—É—Ç–∫–∞ –≤–≤–µ—Ä—Ö")
                self.last_head_action_time = current_time
            except:
                pass
    
    # ============= –û–°–ê–ù–ö–ê - –ò–°–ü–†–ê–í–õ–ï–ù–û =============
    
    def calculate_posture_metrics(self, pose_landmarks):
        """–ú–µ—Ç—Ä–∏–∫–∏ –æ—Å–∞–Ω–∫–∏ - –£–õ–£–ß–®–ï–ù–û"""
        landmarks = pose_landmarks.landmark
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–∏–¥–∏–º–æ—Å—Ç—å –∫–ª—é—á–µ–≤—ã—Ö —Ç–æ—á–µ–∫
        visibility_threshold = 0.5
        required_points = [11, 12, 7, 8, 0]  # –ø–ª–µ—á–∏, —É—à–∏, –Ω–æ—Å
        
        for point in required_points:
            if landmarks[point].visibility < visibility_threshold:
                return None  # –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –≤–∏–¥–∏–º–æ—Å—Ç–∏
        
        # –ö–ª—é—á–µ–≤—ã–µ —Ç–æ—á–∫–∏
        left_shoulder = np.array([landmarks[11].x, landmarks[11].y, landmarks[11].z])
        right_shoulder = np.array([landmarks[12].x, landmarks[12].y, landmarks[12].z])
        left_ear = np.array([landmarks[7].x, landmarks[7].y, landmarks[7].z])
        right_ear = np.array([landmarks[8].x, landmarks[8].y, landmarks[8].z])
        nose = np.array([landmarks[0].x, landmarks[0].y, landmarks[0].z])
        
        # –ú–µ—Ç—Ä–∏–∫–∏
        shoulder_center = (left_shoulder + right_shoulder) / 2
        ear_center = (left_ear + right_ear) / 2
        
        # 1. –ù–∞–∫–ª–æ–Ω –ø–ª–µ—á
        shoulder_angle = math.atan2(
            right_shoulder[1] - left_shoulder[1],
            right_shoulder[0] - left_shoulder[0]
        )
        
        # 2. –í—ã–¥–≤–∏–∂–µ–Ω–∏–µ —à–µ–∏ –≤–ø–µ—Ä–µ–¥
        neck_forward = abs(ear_center[0] - shoulder_center[0])
        
        # 3. –í—ã—Å–æ—Ç–∞ –≥–æ–ª–æ–≤—ã
        head_height = shoulder_center[1] - ear_center[1]
        
        # 4. –ù–∞–∫–ª–æ–Ω –≥–æ–ª–æ–≤—ã –≤–ø–µ—Ä–µ–¥ (Z –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞)
        head_forward_z = ear_center[2] - shoulder_center[2]
        
        return {
            'shoulder_angle': abs(shoulder_angle),
            'neck_forward': neck_forward,
            'head_height': head_height,
            'head_forward_z': head_forward_z,
            'shoulder_y': shoulder_center[1],
            'ear_y': ear_center[1]
        }
    
    def calibrate_posture(self, metrics):
        """–ö–∞–ª–∏–±—Ä–æ–≤–∫–∞ –æ—Å–∞–Ω–∫–∏ - –£–õ–£–ß–®–ï–ù–û"""
        if self.calibration_mode and self.calibration_stage == "posture":
            if metrics is None:
                return False
            
            self.calibration_data.append(metrics)
            self.calibration_frames += 1
            
            if self.calibration_frames >= self.calibration_required:
                # –°—Ä–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –æ—Å–∞–Ω–∫–∏
                self.good_posture_baseline = {
                    'shoulder_angle': np.median([m['shoulder_angle'] for m in self.calibration_data]),
                    'neck_forward': np.median([m['neck_forward'] for m in self.calibration_data]),
                    'head_height': np.median([m['head_height'] for m in self.calibration_data]),
                    'head_forward_z': np.median([m['head_forward_z'] for m in self.calibration_data]),
                    'shoulder_y': np.median([m['shoulder_y'] for m in self.calibration_data]),
                    'ear_y': np.median([m['ear_y'] for m in self.calibration_data])
                }
                
                self.calibration_mode = False
                print("\n‚úÖ –ö–ê–õ–ò–ë–†–û–í–ö–ê –û–°–ê–ù–ö–ò –ó–ê–í–ï–†–®–ï–ù–ê!")
                print(f"   –ë–∞–∑–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è:")
                print(f"   - –£–≥–æ–ª –ø–ª–µ—á: {self.good_posture_baseline['shoulder_angle']:.3f}")
                print(f"   - –®–µ—è –≤–ø–µ—Ä–µ–¥: {self.good_posture_baseline['neck_forward']:.3f}")
                print(f"   - –í—ã—Å–æ—Ç–∞ –≥–æ–ª–æ–≤—ã: {self.good_posture_baseline['head_height']:.3f}\n")
                return True
        return False
    
    def check_posture(self, metrics, current_time):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –æ—Å–∞–Ω–∫–∏ - –ò–°–ü–†–ê–í–õ–ï–ù–û"""
        if self.calibration_mode or self.good_posture_baseline is None or metrics is None:
            return None
        
        if current_time - self.last_posture_check < self.posture_check_interval:
            return None
        
        self.last_posture_check = current_time
        baseline = self.good_posture_baseline
        
        problems = []
        
        # –£–í–ï–õ–ò–ß–ï–ù–´ –ü–û–†–û–ì–ò –¥–ª—è –º–µ–Ω—å—à–∏—Ö –ª–æ–∂–Ω—ã—Ö —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏–π
        
        # 1. –ù–∞–∫–ª–æ–Ω –ø–ª–µ—á - –£–í–ï–õ–ò–ß–ï–ù –ü–û–†–û–ì
        if abs(metrics['shoulder_angle'] - baseline['shoulder_angle']) > 0.25:  # –ë—ã–ª–æ 0.15
            problems.append("–ü–õ–ï–ß–ò –ù–ï–†–û–í–ù–´–ï")
        
        # 2. –®–µ—è –≤–ø–µ—Ä–µ–¥ - –£–í–ï–õ–ò–ß–ï–ù –ü–û–†–û–ì
        if metrics['neck_forward'] > baseline['neck_forward'] + 0.08:  # –ë—ã–ª–æ 0.05
            problems.append("–®–ï–Ø –í–ü–ï–†–ï–î")
            self.slouch_count += 1
        
        # 3. –ì–æ–ª–æ–≤–∞ –æ–ø—É—â–µ–Ω–∞ - –£–í–ï–õ–ò–ß–ï–ù –ü–û–†–û–ì
        if metrics['head_height'] < baseline['head_height'] - 0.06:  # –ë—ã–ª–æ 0.03
            problems.append("–ì–û–õ–û–í–ê –û–ü–£–©–ï–ù–ê")
            self.slouch_count += 1
        
        # 4. –ü–ª–µ—á–∏ –æ–ø—É—â–µ–Ω—ã - –£–í–ï–õ–ò–ß–ï–ù –ü–û–†–û–ì
        if metrics['shoulder_y'] > baseline['shoulder_y'] + 0.08:  # –ë—ã–ª–æ 0.05
            problems.append("–ü–õ–ï–ß–ò –û–ü–£–©–ï–ù–´")
            self.slouch_count += 1
        
        if problems:
            self.slouch_warning_active = True
            return problems
        else:
            self.slouch_warning_active = False
            self.good_posture_count += 1
            if self.slouch_count > 0:
                self.slouch_count -= 1
            return []
    
    # ============= –û–¢–†–ò–°–û–í–ö–ê - –†–£–°–°–ö–ò–ô –Ø–ó–´–ö =============
    
    def draw_info(self, frame, finger_count, gesture_name, blinks_per_min, 
                  ear_value, posture_problems):
        """–û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –ù–ê –†–£–°–°–ö–û–ú"""
        height, width = frame.shape[:2]
        
        # –û—Å–Ω–æ–≤–Ω–æ–π –±–ª–æ–∫
        overlay = frame.copy()
        cv2.rectangle(overlay, (10, 10), (500, 240), (0, 0, 0), -1)
        cv2.addWeighted(overlay, 0.7, frame, 0.3, 0, frame)
        
        y_pos = 35
        
        # –ñ–µ—Å—Ç—ã
        cv2.putText(frame, f"–ñ–µ—Å—Ç: {gesture_name}", (20, y_pos),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
        y_pos += 30
        cv2.putText(frame, f"–ü–∞–ª—å—Ü–µ–≤: {finger_count}", (20, y_pos),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
        y_pos += 30
        
        # –ì–ª–∞–∑–∞
        cv2.putText(frame, f"–ú–æ—Ä–≥–∞–Ω–∏–π/–º–∏–Ω: {blinks_per_min}", (20, y_pos),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)
        y_pos += 25
        
        eye_status = "–ó–∞–∫—Ä—ã—Ç—ã" if ear_value < 0.2 else "–û—Ç–∫—Ä—ã—Ç—ã"
        eye_color = (0, 0, 255) if ear_value < 0.2 else (0, 255, 0)
        cv2.putText(frame, f"–ì–ª–∞–∑–∞: {eye_status}", (20, y_pos),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, eye_color, 2)
        y_pos += 30
        
        # –ö–∞–ª–∏–±—Ä–æ–≤–∫–∞
        if self.calibration_mode:
            progress = int((self.calibration_frames / self.calibration_required) * 100)
            cv2.putText(frame, f"–ö–ê–õ–ò–ë–†–û–í–ö–ê: {progress}%", (20, y_pos),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 255), 2)
            y_pos += 35
            cv2.putText(frame, "–°–ò–î–ò–¢–ï –†–û–í–ù–û!", (20, y_pos),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)
            y_pos += 30
            cv2.putText(frame, "–°–ø–∏–Ω–∞ –ø—Ä—è–º–∞—è, –ø–ª–µ—á–∏ —Ä–∞–∑–≤–µ—Ä–Ω—É—Ç—ã", (20, y_pos),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
        
        # –ü–†–ï–î–£–ü–†–ï–ñ–î–ï–ù–ò–ï –û –°–£–¢–£–õ–û–°–¢–ò - –ë–û–õ–¨–®–û–ï –ù–ê –†–£–°–°–ö–û–ú
        if posture_problems and not self.calibration_mode and len(posture_problems) > 0:
            warning_overlay = frame.copy()
            box_width = 600
            box_height = 150 + len(posture_problems) * 40
            
            cv2.rectangle(warning_overlay, 
                         (width//2 - box_width//2, height//2 - box_height//2),
                         (width//2 + box_width//2, height//2 + box_height//2), 
                         (0, 0, 180), -1)
            cv2.addWeighted(warning_overlay, 0.85, frame, 0.15, 0, frame)
            
            # –ó–∞–≥–æ–ª–æ–≤–æ–∫
            cv2.putText(frame, "–í–´–ü–†–Ø–ú–ò–¢–ï–°–¨!", 
                       (width//2 - 200, height//2 - 50),
                       cv2.FONT_HERSHEY_SIMPLEX, 1.8, (0, 255, 255), 4)
            
            # –ü—Ä–æ–±–ª–µ–º—ã
            y = height//2 + 10
            for problem in posture_problems:
                # –ü–µ—Ä–µ–≤–æ–¥–∏–º –Ω–∞ —Ä—É—Å—Å–∫–∏–π
                problem_ru = problem.replace("–®–ï–Ø –í–ü–ï–†–ï–î", "üî¥ –®–ï–Ø –í–´–¢–Ø–ù–£–¢–ê –í–ü–ï–†–ï–î") \
                                   .replace("–ì–û–õ–û–í–ê –û–ü–£–©–ï–ù–ê", "üî¥ –ì–û–õ–û–í–ê –°–õ–ò–®–ö–û–ú –ù–ò–ó–ö–û") \
                                   .replace("–ü–õ–ï–ß–ò –û–ü–£–©–ï–ù–´", "üî¥ –ü–õ–ï–ß–ò –û–ü–£–©–ï–ù–´") \
                                   .replace("–ü–õ–ï–ß–ò –ù–ï–†–û–í–ù–´–ï", "üî¥ –ü–õ–ï–ß–ò –ù–ê –†–ê–ó–ù–û–ô –í–´–°–û–¢–ï")
                
                cv2.putText(frame, problem_ru, (width//2 - 250, y),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.75, (255, 255, 255), 2)
                y += 40
        
        # –°—á–µ—Ç—á–∏–∫ —Å—É—Ç—É–ª–æ—Å—Ç–∏
        if not self.calibration_mode:
            color = (0, 255, 0) if self.slouch_count < 5 else (0, 165, 255) if self.slouch_count < 10 else (0, 0, 255)
            cv2.putText(frame, f"–°—É—Ç—É–ª–æ—Å—Ç—å: {self.slouch_count}", (width - 250, 35),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)
        
        # –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è
        cv2.putText(frame, "–ù–∞–∂–º–∏—Ç–µ 'q' –¥–ª—è –≤—ã—Ö–æ–¥–∞", (20, height - 20),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
        
        return frame
    
    # ============= –ö–ê–ú–ï–†–ê - –£–õ–£–ß–®–ï–ù–û –î–õ–Ø MACBOOK =============
    
    def find_camera(self):
        """–ü–æ–∏—Å–∫ –∫–∞–º–µ—Ä—ã MacBook - –£–õ–£–ß–®–ï–ù–û"""
        print("üîç –ü–æ–∏—Å–∫ –∫–∞–º–µ—Ä—ã MacBook...")
        
        # –î–ª—è MacBook —Å–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º AVFoundation
        print("   –ü–æ–ø—ã—Ç–∫–∞ 1: AVFoundation (–≤—Å—Ç—Ä–æ–µ–Ω–Ω–∞—è –∫–∞–º–µ—Ä–∞ MacBook)...")
        cap = cv2.VideoCapture(0, cv2.CAP_AVFOUNDATION)
        if cap.isOpened():
            ret, frame = cap.read()
            if ret and frame is not None:
                print("‚úÖ –ù–∞–π–¥–µ–Ω–∞ –≤—Å—Ç—Ä–æ–µ–Ω–Ω–∞—è –∫–∞–º–µ—Ä–∞ MacBook!")
                return cap
            cap.release()
        
        # –ü—Ä–æ–±—É–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –∏–Ω–¥–µ–∫—Å—ã
        for i in [0, 1, 2]:
            print(f"   –ü–æ–ø—ã—Ç–∫–∞ {i+2}: –ö–∞–º–µ—Ä–∞ {i}...")
            cap = cv2.VideoCapture(i)
            if cap.isOpened():
                ret, frame = cap.read()
                if ret and frame is not None:
                    print(f"‚úÖ –ö–∞–º–µ—Ä–∞ –Ω–∞–π–¥–µ–Ω–∞: –∏–Ω–¥–µ–∫—Å {i}")
                    return cap
                cap.release()
        
        return None
    
    # ============= –û–°–ù–û–í–ù–û–ô –¶–ò–ö–õ =============
    
    def run(self):
        """–û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª"""
        cap = self.find_camera()
        if cap is None:
            print("\n‚ùå –ö–ê–ú–ï–†–ê –ù–ï –ù–ê–ô–î–ï–ù–ê!")
            print("\nüîß –í–æ–∑–º–æ–∂–Ω—ã–µ —Ä–µ—à–µ–Ω–∏—è:")
            print("   1. –ó–∞–∫—Ä–æ–π—Ç–µ FaceTime, Zoom, Skype")
            print("   2. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ: –°–∏—Å—Ç–µ–º–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ ‚Üí –ö–∞–º–µ—Ä–∞")
            print("   3. –ü–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∏—Ç–µ MacBook")
            return
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∫–∞–º–µ—Ä—ã
        cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
        cap.set(cv2.CAP_PROP_FPS, 30)
        
        print("\n‚úÖ –°–ò–°–¢–ï–ú–ê –ê–ö–¢–ò–í–ò–†–û–í–ê–ù–ê!")
        print("üéØ –°–Ø–î–¨–¢–ï –†–û–í–ù–û! –ö–∞–ª–∏–±—Ä–æ–≤–∫–∞ –Ω–∞—á–Ω—ë—Ç—Å—è —á–µ—Ä–µ–∑ 3 —Å–µ–∫—É–Ω–¥—ã...\n")
        
        # –ó–∞–¥–µ—Ä–∂–∫–∞ –ø–µ—Ä–µ–¥ –Ω–∞—á–∞–ª–æ–º –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏
        time.sleep(3)
        print("‚ñ∂Ô∏è  –ö–ê–õ–ò–ë–†–û–í–ö–ê –ù–ê–ß–ê–¢–ê! –°–∏–¥–∏—Ç–µ —Ä–æ–≤–Ω–æ...\n")
        
        frame_count = 0
        error_count = 0
        
        try:
            while True:
                success, frame = cap.read()
                if not success or frame is None:
                    error_count += 1
                    if error_count >= 10:
                        print("‚ùå –°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –æ—à–∏–±–æ–∫. –ö–∞–º–µ—Ä–∞ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞.")
                        break
                    time.sleep(0.1)
                    continue
                
                error_count = 0
                frame_count += 1
                current_time = time.time()
                
                frame = cv2.flip(frame, 1)
                rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                
                # –†–£–ö–ò
                hand_results = self.hands.process(rgb_frame)
                finger_count = 0
                gesture_name = "–ù–µ—Ç —Ä—É–∫–∏"
                
                if hand_results.multi_hand_landmarks:
                    for hand_landmarks in hand_results.multi_hand_landmarks:
                        if self.calculate_hand_confidence(hand_landmarks):
                            self.mp_draw.draw_landmarks(
                                frame, hand_landmarks, self.mp_hands.HAND_CONNECTIONS)
                            
                            finger_count = self.count_fingers_optimized(hand_landmarks)
                            gesture_name = self.get_gesture_name(finger_count)
                            
                            if finger_count == self.stable_gesture:
                                self.stable_count += 1
                            else:
                                self.stable_gesture = finger_count
                                self.stable_count = 1
                            
                            if self.stable_count >= self.stability_threshold:
                                self.execute_gesture_action(finger_count)
                                self.stable_count = 0
                
                # –õ–ò–¶–û –ò –ì–õ–ê–ó–ê
                face_results = self.face_mesh.process(rgb_frame)
                eyes_closed = False
                ear_value = 0.3
                
                if face_results.multi_face_landmarks:
                    for face_landmarks in face_results.multi_face_landmarks:
                        eyes_closed, ear_value = self.detect_eye_state(face_landmarks)
                        self.handle_eye_actions(eyes_closed, current_time)
                        
                        # –ì–æ–ª–æ–≤–∞
                        ear_angle, nose_y = self.calculate_head_pose(face_landmarks)
                        self.handle_head_actions(ear_angle, nose_y, current_time)
                
                blinks_per_min = self.check_eye_fatigue(current_time)
                
                # –û–°–ê–ù–ö–ê
                pose_results = self.pose.process(rgb_frame)
                posture_problems = None
                
                if pose_results.pose_landmarks:
                    self.frames_with_pose += 1
                    
                    if self.frames_with_pose >= self.frames_needed_for_detection:
                        metrics = self.calculate_posture_metrics(pose_results.pose_landmarks)
                        
                        if metrics is not None:
                            if self.calibration_mode:
                                self.calibrate_posture(metrics)
                            else:
                                posture_problems = self.check_posture(metrics, current_time)
                        
                        # –†–∏—Å—É–µ–º —Å–∫–µ–ª–µ—Ç (—Ç–æ–ª—å–∫–æ –∫–ª—é—á–µ–≤—ã–µ —Ç–æ—á–∫–∏)
                        # –ü–ª–µ—á–∏ –∏ –≥–æ–ª–æ–≤–∞
                        connections = [
                            (11, 12),  # –ü–ª–µ—á–∏
                            (7, 8),    # –£—à–∏
                            (0, 1),    # –ù–æ—Å
                        ]
                        for connection in connections:
                            start = pose_results.pose_landmarks.landmark[connection[0]]
                            end = pose_results.pose_landmarks.landmark[connection[1]]
                            
                            h, w, _ = frame.shape
                            start_point = (int(start.x * w), int(start.y * h))
                            end_point = (int(end.x * w), int(end.y * h))
                            
                            cv2.line(frame, start_point, end_point, (0, 255, 0), 2)
                            cv2.circle(frame, start_point, 5, (0, 255, 255), -1)
                            cv2.circle(frame, end_point, 5, (0, 255, 255), -1)
                
                # –û–¢–†–ò–°–û–í–ö–ê
                frame = self.draw_info(frame, finger_count, gesture_name,
                                      blinks_per_min, ear_value, posture_problems)
                
                cv2.imshow('AI –°–∏—Å—Ç–µ–º–∞ –£–ø—Ä–∞–≤–ª–µ–Ω–∏—è MacBook', frame)
                
                if cv2.waitKey(1) & 0xFF == ord('q'):
                    print("\nüëã –í—ã—Ö–æ–¥ –∏–∑ –ø—Ä–æ–≥—Ä–∞–º–º—ã...")
                    break
                    
        except KeyboardInterrupt:
            print("\nüëã –ü—Ä–æ–≥—Ä–∞–º–º–∞ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
        except Exception as e:
            print(f"\n‚ùå –û—à–∏–±–∫–∞: {e}")
            import traceback
            traceback.print_exc()
        finally:
            cap.release()
            cv2.destroyAllWindows()
            self.hands.close()
            self.face_mesh.close()
            self.pose.close()
            
            print(f"\nüìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê –°–ï–ê–ù–°–ê:")
            print(f"   ‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –∫–∞–¥—Ä–æ–≤: {frame_count}")
            print(f"   üëÅÔ∏è  –í—Å–µ–≥–æ –º–æ—Ä–≥–∞–Ω–∏–π: {self.blink_count}")
            print(f"   üò¥ –°—É—Ç—É–ª–æ—Å—Ç—å –∑–∞—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–∞: {self.slouch_count} —Ä–∞–∑")
            print(f"   ‚úÖ –•–æ—Ä–æ—à–∞—è –æ—Å–∞–Ω–∫–∞: {self.good_posture_count} –ø—Ä–æ–≤–µ—Ä–æ–∫")
            
            if self.slouch_count > 0:
                print(f"\n‚ö†Ô∏è  –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–Ø: –í—ã —Å—É—Ç—É–ª–∏–ª–∏—Å—å {self.slouch_count} —Ä–∞–∑.")
                print("   –î–µ–ª–∞–π—Ç–µ –ø–µ—Ä–µ—Ä—ã–≤—ã –∫–∞–∂–¥—ã–µ 30 –º–∏–Ω—É—Ç!")
                print("   –°–ª–µ–¥–∏—Ç–µ –∑–∞ –æ—Å–∞–Ω–∫–æ–π!")

def main():
    print("=" * 70)
    print("ü§ñ –ü–û–õ–ù–ê–Ø AI –°–ò–°–¢–ï–ú–ê –£–ü–†–ê–í–õ–ï–ù–ò–Ø MACBOOK")
    print("   –ñ–µ—Å—Ç—ã + –ì–ª–∞–∑–∞ + –ì–æ–ª–æ–≤–∞ + –ö–æ–Ω—Ç—Ä–æ–ª—å –æ—Å–∞–Ω–∫–∏")
    print("   –í–µ—Ä—Å–∏—è 2.0 - –£–ª—É—á—à–µ–Ω–Ω–∞—è –∫–∞–ª–∏–±—Ä–æ–≤–∫–∞")
    print("=" * 70)
    
    controller = UltimateAIController()
    controller.run()

if __name__ == "__main__":
    main()
